{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51df3187",
   "metadata": {},
   "source": [
    "Mediapipe Pose Front Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a1003a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1768018974.420657  181838 gl_context.cc:407] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M3 Max\n",
      "W0000 00:00:1768018974.482737  181840 inference_feedback_manager.cc:121] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1768018974.489196  181840 inference_feedback_manager.cc:121] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration complete. Shoulder threshold: 80.0, Neck threshold: 18.6\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n",
      "Poor posture detected!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 87\u001b[0m\n\u001b[1;32m     85\u001b[0m mp_image \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mImage(image_format\u001b[38;5;241m=\u001b[39mmp\u001b[38;5;241m.\u001b[39mImageFormat\u001b[38;5;241m.\u001b[39mSRGB, data\u001b[38;5;241m=\u001b[39mrgb_frame)\n\u001b[1;32m     86\u001b[0m timestamp_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m results \u001b[38;5;241m=\u001b[39m pose\u001b[38;5;241m.\u001b[39mdetect_for_video(mp_image, timestamp_ms)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:\n\u001b[1;32m     90\u001b[0m     landmarks \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mpose_landmarks[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/mediapipe/tasks/python/vision/pose_landmarker.py:480\u001b[0m, in \u001b[0;36mPoseLandmarker.detect_for_video\u001b[0;34m(self, image, timestamp_ms, image_processing_options)\u001b[0m\n\u001b[1;32m    473\u001b[0m result_c \u001b[38;5;241m=\u001b[39m PoseLandmarkerResultC()\n\u001b[1;32m    475\u001b[0m c_image_processing_options \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    476\u001b[0m     ctypes\u001b[38;5;241m.\u001b[39mbyref(image_processing_options\u001b[38;5;241m.\u001b[39mto_ctypes())\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m image_processing_options\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    479\u001b[0m )\n\u001b[0;32m--> 480\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lib\u001b[38;5;241m.\u001b[39mMpPoseLandmarkerDetectForVideo(\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle,\n\u001b[1;32m    482\u001b[0m     c_image,\n\u001b[1;32m    483\u001b[0m     c_image_processing_options,\n\u001b[1;32m    484\u001b[0m     timestamp_ms,\n\u001b[1;32m    485\u001b[0m     ctypes\u001b[38;5;241m.\u001b[39mbyref(result_c),\n\u001b[1;32m    486\u001b[0m )\n\u001b[1;32m    488\u001b[0m result \u001b[38;5;241m=\u001b[39m PoseLandmarkerResult\u001b[38;5;241m.\u001b[39mfrom_ctypes(result_c)\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lib\u001b[38;5;241m.\u001b[39mMpPoseLandmarkerCloseResult(ctypes\u001b[38;5;241m.\u001b[39mbyref(result_c))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/mediapipe/tasks/python/core/serial_dispatcher.py:74\u001b[0m, in \u001b[0;36mSerialDispatcher._register_signature.<locals>.shutdown_aware_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_closed:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m handler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/mediapipe/tasks/python/core/mediapipe_c_utils.py:142\u001b[0m, in \u001b[0;36mCStatusFunction.create_python_wrapper.<locals>.dispatcher_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error_msg\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m       lib\u001b[38;5;241m.\u001b[39mMpErrorFree(error_msg)\n\u001b[0;32m--> 142\u001b[0m executor\u001b[38;5;241m.\u001b[39msubmit(dispatch_and_free)\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from playsound import playsound\n",
    "\n",
    "# -----------------------------\n",
    "# Landmark indices (stable)\n",
    "# -----------------------------\n",
    "LEFT_EAR = 7\n",
    "RIGHT_EAR = 8\n",
    "LEFT_SHOULDER = 11\n",
    "RIGHT_SHOULDER = 12\n",
    "\n",
    "# -----------------------------\n",
    "# Utility functions\n",
    "# -----------------------------\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    cosine = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-6)\n",
    "    return np.degrees(np.arccos(np.clip(cosine, -1.0, 1.0)))\n",
    "\n",
    "def draw_angle(img, p1, p2, p3, angle, color):\n",
    "    cv2.line(img, p1, p2, color, 2)\n",
    "    cv2.line(img, p2, p3, color, 2)\n",
    "    cv2.putText(img, f\"{angle:.1f}\", (p2[0]+5, p2[1]-5),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "sound_file = \"alert.wav\"  # Sound to play on poor posture\n",
    "alert_cooldown = 5        # seconds between alerts\n",
    "\n",
    "is_calibrated = False\n",
    "calibration_frames = 0\n",
    "calib_shoulder = []\n",
    "calib_neck = []\n",
    "last_alert_time = 0\n",
    "\n",
    "# -----------------------------\n",
    "# MediaPipe PoseLandmarker setup\n",
    "# -----------------------------\n",
    "BaseOptions = python.BaseOptions\n",
    "PoseLandmarker = vision.PoseLandmarker\n",
    "PoseLandmarkerOptions = vision.PoseLandmarkerOptions\n",
    "RunningMode = vision.RunningMode\n",
    "\n",
    "model_path = \"pose_landmarker_lite.task\"\n",
    "assert os.path.exists(model_path), \"Model file 'pose_landmarker_lite.task' not found!\"\n",
    "\n",
    "options = PoseLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=model_path),\n",
    "    running_mode=RunningMode.VIDEO,\n",
    "    num_poses=1,\n",
    "    min_pose_detection_confidence=0.5,\n",
    "    min_pose_presence_confidence=0.5,\n",
    "    min_tracking_confidence=0.5,\n",
    ")\n",
    "\n",
    "pose = PoseLandmarker.create_from_options(options)\n",
    "\n",
    "# -----------------------------\n",
    "# Webcam\n",
    "# -----------------------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# -----------------------------\n",
    "# Main loop\n",
    "# -----------------------------\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    h, w, _ = frame.shape\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
    "    timestamp_ms = int(time.time()*1000)\n",
    "    results = pose.detect_for_video(mp_image, timestamp_ms)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        landmarks = results.pose_landmarks[0]\n",
    "\n",
    "        def lm(i):\n",
    "            return int(landmarks[i].x * w), int(landmarks[i].y * h)\n",
    "\n",
    "        left_shoulder = lm(LEFT_SHOULDER)\n",
    "        right_shoulder = lm(RIGHT_SHOULDER)\n",
    "        left_ear = lm(LEFT_EAR)\n",
    "        right_ear = lm(RIGHT_EAR)\n",
    "\n",
    "        mid_shoulder = ((left_shoulder[0]+right_shoulder[0])//2,\n",
    "                        (left_shoulder[1]+right_shoulder[1])//2)\n",
    "\n",
    "        # Calculate angles for both sides\n",
    "        shoulder_angle_left = calculate_angle(left_shoulder, mid_shoulder, (mid_shoulder[0],0))\n",
    "        shoulder_angle_right = calculate_angle(right_shoulder, mid_shoulder, (mid_shoulder[0],0))\n",
    "        neck_angle_left = calculate_angle(left_ear, left_shoulder, (left_shoulder[0],0))\n",
    "        neck_angle_right = calculate_angle(right_ear, right_shoulder, (right_shoulder[0],0))\n",
    "\n",
    "        # -----------------------------\n",
    "        # Calibration (first 30 frames)\n",
    "        # -----------------------------\n",
    "        if not is_calibrated and calibration_frames < 30:\n",
    "            calib_shoulder.append(shoulder_angle_left)\n",
    "            calib_shoulder.append(shoulder_angle_right)\n",
    "            calib_neck.append(neck_angle_left)\n",
    "            calib_neck.append(neck_angle_right)\n",
    "            calibration_frames += 1\n",
    "            cv2.putText(frame, f\"Calibrating {calibration_frames}/30\",\n",
    "                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,255), 2)\n",
    "        elif not is_calibrated:\n",
    "            shoulder_thresh = np.mean(calib_shoulder) - 10\n",
    "            neck_thresh = np.mean(calib_neck) - 10\n",
    "            is_calibrated = True\n",
    "            print(f\"Calibration complete. Shoulder threshold: {shoulder_thresh:.1f}, Neck threshold: {neck_thresh:.1f}\")\n",
    "\n",
    "        # -----------------------------\n",
    "        # Draw landmarks\n",
    "        # -----------------------------\n",
    "        for pt in landmarks:\n",
    "            cx, cy = int(pt.x * w), int(pt.y * h)\n",
    "            cv2.circle(frame, (cx, cy), 3, (0,255,0), -1)\n",
    "\n",
    "        # Draw angles\n",
    "        draw_angle(frame, left_shoulder, mid_shoulder, (mid_shoulder[0],0), shoulder_angle_left, (255,0,0))\n",
    "        draw_angle(frame, right_shoulder, mid_shoulder, (mid_shoulder[0],0), shoulder_angle_right, (0,0,255))\n",
    "        draw_angle(frame, left_ear, left_shoulder, (left_shoulder[0],0), neck_angle_left, (0,255,0))\n",
    "        draw_angle(frame, right_ear, right_shoulder, (right_shoulder[0],0), neck_angle_right, (0,255,255))\n",
    "\n",
    "        # -----------------------------\n",
    "        # Feedback (trigger if either side off threshold)\n",
    "        # -----------------------------\n",
    "        if is_calibrated:\n",
    "            now = time.time()\n",
    "            poor_posture = (\n",
    "                shoulder_angle_left < shoulder_thresh or\n",
    "                shoulder_angle_right < shoulder_thresh or\n",
    "                neck_angle_left < neck_thresh or\n",
    "                neck_angle_right < neck_thresh\n",
    "            )\n",
    "\n",
    "            if poor_posture:\n",
    "                status = \"Poor Posture\"\n",
    "                color = (0,0,255)\n",
    "                if now - last_alert_time > alert_cooldown:\n",
    "                    print(\"Poor posture detected!\")\n",
    "                    if os.path.exists(sound_file):\n",
    "                        playsound(sound_file)\n",
    "                    last_alert_time = now\n",
    "            else:\n",
    "                status = \"Good Posture\"\n",
    "                color = (0,255,0)\n",
    "\n",
    "            # Display status and angles\n",
    "            cv2.putText(frame, status, (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, color,2)\n",
    "            cv2.putText(frame, f\"Shoulder L/R: {shoulder_angle_left:.1f}/{shoulder_angle_right:.1f}\",\n",
    "                        (10,60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255),1)\n",
    "            cv2.putText(frame, f\"Neck L/R: {neck_angle_left:.1f}/{neck_angle_right:.1f}\",\n",
    "                        (10,90), cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,255,255),1)\n",
    "\n",
    "    cv2.imshow(\"Posture Corrector\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
