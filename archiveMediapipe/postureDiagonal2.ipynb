{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd6814e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1768023693.061025  246737 gl_context.cc:407] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M3 Max\n",
      "W0000 00:00:1768023693.130631  246739 inference_feedback_manager.cc:121] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1768023693.137292  246739 inference_feedback_manager.cc:121] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration done. head_thresh=137.9, back_thresh=178.6\n",
      "Alert: Poor posture!\n",
      "Alert: Poor posture!\n",
      "Alert: Poor posture!\n",
      "Alert: Poor posture!\n",
      "Alert: Poor posture!\n",
      "Alert: Poor posture!\n",
      "Alert: Poor posture!\n",
      "Alert: Poor posture!\n",
      "Alert: Poor posture!\n",
      "Alert: Poor posture!\n",
      "Alert: Poor posture!\n",
      "Alert: Poor posture!\n",
      "Alert: Poor posture!\n",
      "Alert: Poor posture!\n",
      "Alert: Poor posture!\n",
      "Alert: Poor posture!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from playsound import playsound\n",
    "\n",
    "# -----------------------------\n",
    "# Landmark indices\n",
    "# -----------------------------\n",
    "NOSE = 0\n",
    "LEFT_EAR = 7\n",
    "RIGHT_EAR = 8\n",
    "LEFT_SHOULDER = 11\n",
    "RIGHT_SHOULDER = 12\n",
    "\n",
    "# -----------------------------\n",
    "# Helper functions\n",
    "# -----------------------------\n",
    "def angle_between_vectors(v1, v2):\n",
    "    \"\"\"\n",
    "    Returns angle (degrees) between two 3D vectors\n",
    "    \"\"\"\n",
    "    v1, v2 = np.array(v1), np.array(v2)\n",
    "    cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1)*np.linalg.norm(v2) + 1e-6)\n",
    "    return np.degrees(np.arccos(np.clip(cos_angle, -1, 1)))\n",
    "\n",
    "def lm3d(landmark):\n",
    "    \"\"\"\n",
    "    Convert a landmark to 3D NumPy array\n",
    "    \"\"\"\n",
    "    return np.array([landmark.x, landmark.y, landmark.z])\n",
    "\n",
    "def draw_skeleton(frame, landmarks, color=(0, 255, 0)):\n",
    "    \"\"\"\n",
    "    Draw upper-body skeleton lines\n",
    "    \"\"\"\n",
    "    h, w, _ = frame.shape\n",
    "    def to_pixel(l):\n",
    "        return int(l.x * w), int(l.y * h)\n",
    "    \n",
    "    left_sh = to_pixel(landmarks[LEFT_SHOULDER])\n",
    "    right_sh = to_pixel(landmarks[RIGHT_SHOULDER])\n",
    "    nose = to_pixel(landmarks[NOSE])\n",
    "    left_ear = to_pixel(landmarks[LEFT_EAR])\n",
    "    right_ear = to_pixel(landmarks[RIGHT_EAR])\n",
    "\n",
    "    # Shoulder line\n",
    "    cv2.line(frame, left_sh, right_sh, color, 2)\n",
    "    # Nose to mid-shoulder\n",
    "    mid_sh = ((left_sh[0]+right_sh[0])//2, (left_sh[1]+right_sh[1])//2)\n",
    "    cv2.line(frame, nose, mid_sh, color, 2)\n",
    "    # Optional: head connections\n",
    "    cv2.line(frame, nose, left_ear, color, 1)\n",
    "    cv2.line(frame, nose, right_ear, color, 1)\n",
    "    # Draw landmarks\n",
    "    for p in [left_sh, right_sh, nose, left_ear, right_ear]:\n",
    "        cv2.circle(frame, p, 5, color, -1)\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "sound_file = \"alert.wav\"\n",
    "alert_cooldown = 5\n",
    "\n",
    "is_calibrated = False\n",
    "calibration_frames = 0\n",
    "head_tilts = []\n",
    "back_tilts = []\n",
    "last_alert_time = 0\n",
    "\n",
    "# -----------------------------\n",
    "# MediaPipe PoseLandmarker setup\n",
    "# -----------------------------\n",
    "BaseOptions = python.BaseOptions\n",
    "PoseLandmarker = vision.PoseLandmarker\n",
    "PoseLandmarkerOptions = vision.PoseLandmarkerOptions\n",
    "RunningMode = vision.RunningMode\n",
    "\n",
    "model_path = \"pose_landmarker_lite.task\"\n",
    "assert os.path.exists(model_path), \"pose_landmarker_lite.task not found!\"\n",
    "\n",
    "options = PoseLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=model_path),\n",
    "    running_mode=RunningMode.VIDEO,\n",
    "    num_poses=1,\n",
    "    min_pose_detection_confidence=0.5,\n",
    "    min_pose_presence_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "pose = PoseLandmarker.create_from_options(options)\n",
    "\n",
    "# -----------------------------\n",
    "# Start webcam\n",
    "# -----------------------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# -----------------------------\n",
    "# Main loop\n",
    "# -----------------------------\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
    "    timestamp_ms = int(time.time()*1000)\n",
    "\n",
    "    results = pose.detect_for_video(mp_image, timestamp_ms)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        l = results.pose_landmarks[0]\n",
    "\n",
    "        left_sh = lm3d(l[LEFT_SHOULDER])\n",
    "        right_sh = lm3d(l[RIGHT_SHOULDER])\n",
    "        nose = lm3d(l[NOSE])\n",
    "\n",
    "        # Mid-shoulder\n",
    "        mid_shoulder = (left_sh + right_sh)/2\n",
    "\n",
    "        # -------------------------\n",
    "        # Posture metrics\n",
    "        # -------------------------\n",
    "        # Forward head / slouch: angle nose -> mid-shoulder vs vertical\n",
    "        head_vec = mid_shoulder - nose\n",
    "        head_tilt = angle_between_vectors(head_vec, [0, -1, 0])\n",
    "\n",
    "        # Upper back tilt: shoulder line vs horizontal\n",
    "        shoulder_vec = right_sh - left_sh\n",
    "        back_tilt = angle_between_vectors(shoulder_vec, [1, 0, 0])\n",
    "\n",
    "        # -------------------------\n",
    "        # Calibration\n",
    "        # -------------------------\n",
    "        if not is_calibrated and calibration_frames < 30:\n",
    "            head_tilts.append(head_tilt)\n",
    "            back_tilts.append(back_tilt)\n",
    "            calibration_frames += 1\n",
    "            cv2.putText(frame, f\"Calibrating {calibration_frames}/30\", (10,30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,255), 2)\n",
    "        elif not is_calibrated:\n",
    "            head_thresh = np.mean(head_tilts) + 20\n",
    "            back_thresh = np.mean(back_tilts) + 20\n",
    "            is_calibrated = True\n",
    "            print(f\"Calibration done. head_thresh={head_thresh:.1f}, back_thresh={back_thresh:.1f}\")\n",
    "\n",
    "        # -------------------------\n",
    "        # Feedback\n",
    "        # -------------------------\n",
    "        if is_calibrated:\n",
    "            poor_posture = head_tilt > head_thresh or back_tilt < back_thresh\n",
    "            now = time.time()\n",
    "            if poor_posture:\n",
    "                status = \"Poor Posture\"\n",
    "                color = (0,0,255)\n",
    "                if now - last_alert_time > alert_cooldown:\n",
    "                    print(\"Alert: Poor posture!\")\n",
    "                    if os.path.exists(sound_file):\n",
    "                        playsound(sound_file)\n",
    "                    last_alert_time = now\n",
    "            else:\n",
    "                status = \"Good Posture\"\n",
    "                color = (0,255,0)\n",
    "\n",
    "            # Draw skeleton and angles\n",
    "            draw_skeleton(frame, l, color=color)\n",
    "            cv2.putText(frame, status, (10,30), cv2.FONT_HERSHEY_SIMPLEX,1,color,2)\n",
    "            cv2.putText(frame, f\"Head tilt: {head_tilt:.1f}\", (10,60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,255,255),1)\n",
    "            cv2.putText(frame, f\"Back tilt: {back_tilt:.1f}\", (10,90),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,255,255),1)\n",
    "\n",
    "    # Show frame\n",
    "    cv2.imshow(\"Table Posture Detector\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
